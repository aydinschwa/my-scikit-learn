{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "315b6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4b601258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- decision trees are greedy: they will take the predictor that minimizes the chosen loss function at each level.\n",
    "- To decide, we split the tree into leaves based on the label values of a predictor. The more \"pure\" each leaf is,\n",
    "  the better that split is. So we choose the split that makes the best leaves.\n",
    "- Gini Impurity: 1 - p(being in one group)^2 - p(probability of being in the other group)^2\n",
    "- different for numeric data: need to sort obs from lowest to highest value. Then split sequentially starting with \n",
    "  there being two leaves of size 1 and n-1, and finishing with leaves of size n-1 and 1. Calculate the weighted \n",
    "  average impurity of each split, pick the split that gives the lowest average impurity.\n",
    "- continue splitting tree until we reach some depth k or we reach a pure node\n",
    "\n",
    "process for decision tree: \n",
    "    1. for each variable, calculate the gini impurity of using it to split the target into groups\n",
    "        a. For categorical variables, do this by splitting into groups based on category labels and\n",
    "           calculating the gini impurity for each new node. Then average that impurity for a score.\n",
    "        b. For numeric variables, sort the values and create an expanding window of splits into a\n",
    "           less than leaf and a greater than leaf. Choose the split pair that minimized the gini impurity.\n",
    "    2. Recursively do this for each new node until you reach completely pure nodes OR you reach an \n",
    "       arbitrary depth k. \n",
    "    3. To predict new values, just run it through the prebuilt decision tree.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class dTree:\n",
    "    def __init__(self, k=0):\n",
    "        self.l_child = None\n",
    "        self.r_child = None\n",
    "        self.k = k\n",
    "        self.split_col = None\n",
    "        self.split_val = None\n",
    "        self.is_leaf = False\n",
    "        self.y_vals = []\n",
    "        \n",
    "    def find_best_split(self, data, target):\n",
    "        min_gini = 9999999\n",
    "        best_col = None\n",
    "        best_split = None\n",
    "\n",
    "        for col_idx in range(len(data[0])):\n",
    "            sorted_x = data[data[:, col_idx].argsort()]\n",
    "            sorted_y = target[data[:, col_idx].argsort()]\n",
    "\n",
    "            for row_idx in range(len(data) - 1):\n",
    "                lesser_half = sorted_y[sorted_x[:, col_idx] <= sorted_x[row_idx][col_idx]]\n",
    "                greater_half = sorted_y[sorted_x[:, col_idx] > sorted_x[row_idx][col_idx]]\n",
    "                avg_gini = (gini(lesser_half) + gini(greater_half)) / 2\n",
    "                if avg_gini < min_gini:\n",
    "                    best_col = col_idx\n",
    "                    best_split = sorted_x[row_idx][col_idx]\n",
    "                    min_gini = avg_gini\n",
    "                if min_gini == 0:\n",
    "                    break\n",
    "            if min_gini == 0:\n",
    "                break\n",
    "                \n",
    "            \n",
    "        return best_col, best_split, min_gini\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        split_col, split_val, min_gini = self.find_best_split(X, y)\n",
    "        self.split_col = split_col\n",
    "        self.split_val = split_val\n",
    "\n",
    "        lesser_criteria = X[:, split_col] <= split_val\n",
    "        greater_criteria = X[:, split_col] > split_val\n",
    "        if len(y[lesser_criteria]) < 3 or len(y[greater_criteria]) < 3:\n",
    "            self.is_leaf = True\n",
    "            self.y_vals = y\n",
    "        else:\n",
    "            self.l_child = dTree(self.k + 1).fit(X[lesser_criteria], y[lesser_criteria])\n",
    "            self.r_child = dTree(self.k + 1).fit(X[greater_criteria], y[greater_criteria])\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.l_child:\n",
    "            return np.bincount(self.y_vals).argmax()\n",
    "        if X[self.split_col] <= self.split_val:\n",
    "            return self.l_child.predict(X)\n",
    "        else:\n",
    "            return self.r_child.predict(X)\n",
    "    \n",
    "    def gini(self, y):\n",
    "        # get count of each unique value in the dataset\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        # gini impurity formula\n",
    "        impurity = 1 - np.sum((counts / len(y))**2)\n",
    "        return impurity\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# note: all iris data is numeric\n",
    "\n",
    "iris_df = sklearn.datasets.load_iris()\n",
    "data = iris_df[\"data\"]\n",
    "target = iris_df[\"target\"]\n",
    "\n",
    "tree = dTree().fit(data, target)\n",
    "print(tree.predict(iris_df[\"data\"][a]))\n",
    "print(iris_df[\"target\"][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1b162ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.0% accurate\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(iris_df[\"data\"])):\n",
    "    pred = tree.predict(iris_df[\"data\"][i])\n",
    "    true = iris_df[\"target\"][i]\n",
    "    if pred == true:\n",
    "        correct += 1        \n",
    "print(f\"{correct / len(iris_df['data']) * 100}% accurate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
