{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "63960d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a28564c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DecisionTreeBase:\n",
    "    def __init__(self, depth=0, max_depth=15, min_samples=1, max_features=None):\n",
    "        self.l_child = None\n",
    "        self.r_child = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.depth = depth\n",
    "        self.max_features = max_features\n",
    "        self.split_col = None\n",
    "        self.split_val = None\n",
    "        self.is_leaf = False\n",
    "        self.y_vals = []\n",
    "        \n",
    "    def find_best_split(self, data, target):\n",
    "        min_loss = math.inf\n",
    "        best_col = None\n",
    "        best_split = None\n",
    "\n",
    "        cols = range(len(data[0]))\n",
    "        if self.max_features:\n",
    "            cols = np.random.choice((cols), size=self.max_features, replace=False)\n",
    "\n",
    "        for col_idx in cols: \n",
    "\n",
    "            for row_idx in range(len(data) - 1):\n",
    "                lesser_half = target[data[:, col_idx] <= data[row_idx][col_idx]]\n",
    "                greater_half = target[data[:, col_idx] > data[row_idx][col_idx]]\n",
    "                current_loss = self.loss(lesser_half, greater_half)\n",
    "                if current_loss < min_loss:\n",
    "                    best_col = col_idx\n",
    "                    best_split = data[row_idx][col_idx]\n",
    "                    min_loss = current_loss \n",
    "                if min_loss == 0:\n",
    "                    break\n",
    "            if min_loss == 0:\n",
    "                break\n",
    "                \n",
    "        return best_col, best_split \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        split_col, split_val = self.find_best_split(X, y)\n",
    "        self.split_col = split_col\n",
    "        self.split_val = split_val\n",
    "\n",
    "        if not split_val:\n",
    "            self.is_leaf = True\n",
    "            self.y_vals = y\n",
    "            return\n",
    "\n",
    "        lesser_criteria = X[:, split_col] <= split_val\n",
    "        greater_criteria = X[:, split_col] > split_val\n",
    "\n",
    "        if len(y[lesser_criteria]) < self.min_samples or len(y[greater_criteria]) < self.min_samples:\n",
    "            self.is_leaf = True\n",
    "            self.y_vals = y\n",
    "            \n",
    "        else:\n",
    "            self.l_child = type(self)(self.depth + 1)\n",
    "            self.l_child.fit(X[lesser_criteria], y[lesser_criteria])\n",
    "            self.r_child = type(self)(self.depth + 1)\n",
    "            self.r_child.fit(X[greater_criteria], y[greater_criteria])\n",
    "            \n",
    "    def predict(self, X):\n",
    "        if self.is_leaf:\n",
    "            return self.leaf_predict(self.y_vals)\n",
    "        if X[self.split_col] <= self.split_val:\n",
    "            return self.l_child.predict(X)\n",
    "        else:\n",
    "            return self.r_child.predict(X)\n",
    "\n",
    "    # to be implemented by child classes\n",
    "    def loss(self, less_half, greater_half):\n",
    "        return None\n",
    "\n",
    "    def leaf_predict(self, y):\n",
    "        return None\n",
    "    \n",
    "\n",
    "class DecisionTreeClassifier(DecisionTreeBase):\n",
    "    \n",
    "    def loss(self, less, greater):\n",
    "        def get_impurity(vals):\n",
    "            # get count of each unique value in the dataset\n",
    "            _, counts = np.unique(vals, return_counts=True)\n",
    "\n",
    "            # gini impurity formula\n",
    "            impurity = 1 - np.sum((counts / len(vals))**2)\n",
    "            return impurity\n",
    "\n",
    "        return (get_impurity(less) + get_impurity(greater)) / 2\n",
    "\n",
    "    def leaf_predict(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "\n",
    "class DecisionTreeRegressor(DecisionTreeBase):\n",
    "\n",
    "    def loss(self, less, greater):\n",
    "        def sum_sq_error(vals):\n",
    "            return np.sum((vals - np.mean(vals))**2)\n",
    "        \n",
    "        return sum_sq_error(less) + sum_sq_error(greater)\n",
    "\n",
    "    def leaf_predict(self, y):\n",
    "        return np.mean(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec15be",
   "metadata": {},
   "source": [
    "# Testing Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "009e47f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# note: all iris data is numeric\n",
    "\n",
    "iris_df = sklearn.datasets.load_iris()\n",
    "data = iris_df[\"data\"]\n",
    "target = iris_df[\"target\"]\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(data, target)\n",
    "a = 10\n",
    "print(tree.predict(iris_df[\"data\"][a]))\n",
    "print(iris_df[\"target\"][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ecd358cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% accurate\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(iris_df[\"data\"])):\n",
    "    pred = tree.predict(iris_df[\"data\"][i])\n",
    "    true = iris_df[\"target\"][i]\n",
    "    if pred == true:\n",
    "        correct += 1        \n",
    "print(f\"{correct / len(iris_df['data']) * 100}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48805e",
   "metadata": {},
   "source": [
    "# Testing Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f5de9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, target):\n",
    "    return np.sqrt(np.sum(np.power(predicted - target, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a050b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = sklearn.datasets.load_diabetes()\n",
    "data = diabetes_df[\"data\"]\n",
    "target = diabetes_df[\"target\"]\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(data, target)\n",
    "pred = [tree.predict(diabetes_df[\"data\"][i]) for i in range(len(target))]\n",
    "rmse(pred, diabetes_df[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "985e8852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Train the regressor\n",
    "regressor.fit(data, target)\n",
    "\n",
    "y_pred = regressor.predict(data)\n",
    "rmse(y_pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f3fae",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a5278da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def bootstrap(X):\n",
    "    bootstrap_indices = np.random.randint(len(X), size=len(X))\n",
    "    oob_indices = set(range(len(X))).difference(set(bootstrap_indices))\n",
    "    return bootstrap_indices, np.array(oob_indices)\n",
    "\n",
    "\n",
    "class RandomForestClassifier:\n",
    "\n",
    "    def __init__(self, n_estimators=20, max_features=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = int(math.sqrt(max_features))\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            bootstrap_indices, oob_indices = bootstrap(X)\n",
    "            tree = DecisionTreeClassifier(max_features=self.max_features)\n",
    "            tree.fit(X[bootstrap_indices], y[bootstrap_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(np.bincount([tree.predict(X) for tree in self.trees]))\n",
    "\n",
    "iris_df = sklearn.datasets.load_iris()\n",
    "data = iris_df[\"data\"]\n",
    "target = iris_df[\"target\"]\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(data, target)\n",
    "rf.predict(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "7754a5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473.8720238629835"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class RandomForestRegressor:\n",
    "\n",
    "    def __init__(self, n_estimators=20, max_features=False):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            bootstrap_indices, oob_indices = bootstrap(X)\n",
    "            tree = DecisionTreeRegressor()\n",
    "            tree.fit(X[bootstrap_indices], y[bootstrap_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions= []\n",
    "        for sample in X:\n",
    "            predictions.append(np.mean([tree.predict([sample]) for tree in self.trees]))\n",
    "        return np.array(predictions) \n",
    "\n",
    "\n",
    "diabetes_df = sklearn.datasets.load_diabetes()\n",
    "data = diabetes_df[\"data\"]\n",
    "target = diabetes_df[\"target\"]\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(data, target)\n",
    "y_pred = rf.predict(data)\n",
    "\n",
    "rmse(y_pred, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "456c5b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457.3278052994373"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "diabetes_df = sklearn.datasets.load_diabetes()\n",
    "data = diabetes_df[\"data\"]\n",
    "target = diabetes_df[\"target\"]\n",
    "\n",
    "# Train the regressor\n",
    "regressor.fit(data, target)\n",
    "\n",
    "y_pred = regressor.predict(data)\n",
    "rmse(y_pred, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
